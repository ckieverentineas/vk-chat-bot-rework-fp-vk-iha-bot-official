import { tokenizer, tokenizer_sentence } from "..";
import { WordTokenizer, JaroWinklerDistance } from "natural";
import prisma from "./prisma";

function tokenizeText(text: string): string[][] {
  const sentences: string[] = tokenizer_sentence.tokenize(text.toLowerCase());
  const words: string[][] = sentences.map((sentence: string) => tokenizer.tokenize(sentence));
  return words;
}

async function* Generator_Sentence() {
  const batchSize = 100000;
  let cursor: number | undefined = undefined;
  while (true) {
    const sentences: any = await prisma.answer.findMany({
      take: batchSize,
      skip: cursor ?? 0,
      cursor: cursor ? { id: cursor } : undefined,
      orderBy: { id: 'asc' },
    });
    if (!sentences.length) break;
    yield sentences;
    cursor = sentences[sentences.length - 1].id;
  }
}

function findClosestMatch(query: string, sentences: string[]): { sentence: string, query: string } | undefined {
    // –ü—Ä–∏–≤–æ–¥–∏–º –∑–∞–ø—Ä–æ—Å –∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
    query = query.toLowerCase();
    const sentencesLower = sentences.map(sentence => {
      if (typeof sentence === "string") {
        return sentence.toLowerCase();
      } else {
        return "";
      }
    });
  
    // –†–∞–∑–±–∏–≤–∞–µ–º –∑–∞–ø—Ä–æ—Å –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞
    const tokenizer = new WordTokenizer();
    const queryWords = tokenizer.tokenize(query);
  
    // –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    const contextWords = queryWords;
  
    // –í—ã—á–∏—Å–ª—è–µ–º —Å—Ö–æ–∂–µ—Å—Ç—å –º–µ–∂–¥—É –∫–∞–∂–¥—ã–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º –∏ –∑–∞–ø—Ä–æ—Å–æ–º,
    // –∏—Å–ø–æ–ª—å–∑—É—è —Ñ—É–Ω–∫—Ü–∏—é JaroWinklerDistance –∏–∑ –º–æ–¥—É–ª—è "natural"
    const matches = sentencesLower.map(sentenceLower => ({
      sentence: sentenceLower,
      score: JaroWinklerDistance( query, sentenceLower, {} ),
    }));
  
    // –°–æ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ —É–±—ã–≤–∞–Ω–∏—é —Å—Ö–æ–∂–µ—Å—Ç–∏
    matches.sort((a, b) => b.score - a.score);
  
    // –ù–∞—Ö–æ–¥–∏–º –Ω–∞–∏–ª—É—á—à–µ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ, —É—á–∏—Ç—ã–≤–∞—è –∫–æ–Ω—Ç–µ–∫—Å—Ç
    const bestMatch = matches.find(match => {
      const matchWords = tokenizer.tokenize(match.sentence);
      const intersection = matchWords.filter(word => contextWords.includes(word));
      return intersection.length > 0;
    });
  
    // –ï—Å–ª–∏ –Ω–∞—à–ª–æ—Å—å —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –µ–≥–æ
    if (bestMatch) {
      return { sentence: bestMatch.sentence, query: query };
    } else {
      return undefined;
    }
  }

async function processText(text: string): Promise<{ sentence: string, query: string }[]> {
  const tokenizedText = tokenizeText(text);
  const generator = Generator_Sentence();
  let result: { sentence: string, query: string }[] = [];
  for await (const sentences of generator) {
    const similarities: any = tokenizedText.map(query => findClosestMatch(query.join(" "), sentences.map((sent:any) => sent.answer))).filter(Boolean);
    if (!similarities.length) continue;
    const similaritiesWithQuery = similarities.map((similarity: { sentence: string, query: string }) => ({
      sentence: similarity.sentence,
      query: similarity.query
    }));
    result = result.concat(similaritiesWithQuery);
  }
  return result;
}

async function generateBestSentences(text: string): Promise<{ sentence: string, query: string }[]> {
    const search_all = await processText(text); // –∏–∑–º–µ–Ω–µ–Ω–Ω—ã–π –∫–æ–¥
    const uniqueQueries = Array.from(new Set(search_all.map(item => item.query))); // –∏–∑–º–µ–Ω–µ–Ω–Ω—ã–π –∫–æ–¥
    const bestSentences: { sentence: string, query: string }[] = [];
  
    for (const query of uniqueQueries) {
      const sentences = search_all.filter(item => item.query === query).map(item => item.sentence);
      const bestSentence = findClosestMatch(query, sentences)?.sentence;
      if (bestSentence) {
        bestSentences.push({ query, sentence: bestSentence });
      }
    }
  
    return bestSentences;
  }
  async function Engine_Generate_Last_Age(text: string) {
    const search_all = await processText(text);
    const search_best = await generateBestSentences(text); // –∏–∑–º–µ–Ω–µ–Ω–Ω—ã–π –∫–æ–¥
    console.log("üöÄ ~ file: reseacher_parallel.ts:103 ~ Engine_Generate_Last_Age ~ search_best:", search_best)
  }

export default Engine_Generate_Last_Age;